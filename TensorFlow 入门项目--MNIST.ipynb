{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 机器学习入门\n",
    "---\n",
    "> 引言：编程入门有‘Hello world’ , ML 入门有‘MNIST’\n",
    "\n",
    "### 简介\n",
    "---\n",
    "MNIST 是一个入门级的计算机视觉数据集，他包含：\n",
    "* 各种手写数字图片（x 值 -- 试卷）\n",
    "* 每一张图片对应的标签（y 值 -- 答案）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练/测试数据集获取\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行这段 code，回去 执行 input_data.py 这个文件中的方法，download 相关的数据集\n",
    "import input_data\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "---\n",
    "$ y = softmax(Wx + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# init x , None means 第一维度可以是 任意长度 的值\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#  模型实现 ( y = Wx + b)\n",
    "#  Wx + b 的结果输入到 tf.nn.softmax() 函数中\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "---\n",
    "这个时候，到<u>**损失函数**</u>登场了\n",
    "\n",
    "一种常见、漂亮的成本函数：\"交叉熵\"（cross-entropy）\n",
    "$$\n",
    "H_y^|(y) =  -\\sum_i{y^|_ilog(y_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "# 计算 交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了交叉熵（loss(y)）,现在要开始优化啦，用<u>**梯度下降**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 梯度下降算法（gradient descent algorithm）\n",
    "# 学习率 0.01\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型建立完毕，要启动啦\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # loop 1000 times\n",
    "    for i in range(1000):\n",
    "        # 随机抓取训练数据中的100个批处理数据点\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        # 把真实值给 y_ , input数据给 x ，开始训练\n",
    "        sess.run(train_step, feed_dict={x:batch_xs, y_:batch_ys})\n",
    "    # 评估模型\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    # bool 转 float ----> tf.cast()\n",
    "    # 求平均值 -----> tf.reduct_mean()\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估模型\n",
    "---\n",
    "* `tf.argmax`：一个有用的函数，能给出tensor 对象在某一维度上的其数据最大值所在的索引值。\n",
    "例如：\n",
    "`tf.argmax(y, 1)`表示模型对于任一输入x预测得到的 标签值\n",
    "`tf.argmax(y_, 1)`代表正确的标签\n",
    "用`tf.equal` 检测我们的预测是否真实标签匹配（索引 位置一样表示匹配）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
